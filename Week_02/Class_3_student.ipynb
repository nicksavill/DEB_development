{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d03e30",
   "metadata": {},
   "source": [
    "### Cleaning, tidying and re-arranging your data\n",
    "\n",
    "It is very rare for a dataset to be in the exact format you'd like, with just the data you want and no errors.  Much of the work in data analysis is producing a tidy dataset ready to work with.  80% of data analysis is spent on the process of cleaning and preparing the data (Dasu and Johnson 2003).  In this week's classes you will learn about:  \n",
    "\n",
    "Adding/removing columns  \n",
    "Combining columns  \n",
    "Filtering data - by rows, columns  \n",
    "Transforming data - operations over series  \n",
    "Tidy data\n",
    "Changing form of data - melt, pivot  \n",
    "\n",
    "\n",
    "In Class 3 you will learn about tidy data and more advanced ways of manipulating data into useful forms.\n",
    "In Class 4 you'll practise these processes on a dataset of your choice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418db4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f2c16",
   "metadata": {},
   "source": [
    "### Introduction - basic changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496a114",
   "metadata": {},
   "source": [
    "Read in one of last week's dataframes  - count.csv in the datassets folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f842a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4f3f2d2",
   "metadata": {},
   "source": [
    "The index is not doing anything useful here.  We can read in with the field names as the index by adding:  \n",
    "\n",
    "    index_col = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00f64c",
   "metadata": {},
   "source": [
    "We'll add two new columns - one of Soil types, one of Drainage. Here they are as lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Sand\",\"Loam\",\"Loam\",\"Clay\",\"Clay\",\"Loam\",\"Sand\",\"Sand\",\"Clay\",\"Clay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dcd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"Good\", \"OK\", \"Poor\", \"Poor\", \"Poor\", \"Good\", \"Good\", \"OK\", \"OK\",\"Poor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fecd1d4",
   "metadata": {},
   "source": [
    "Make the new columns from the list like this:  \n",
    "    \n",
    "    df[\"COLUMN_NAME\"] = [LIST]\n",
    "    \n",
    "Check the columns have been added correclty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2ad25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb35f361",
   "metadata": {},
   "source": [
    "Here's one way to drop a column:  \n",
    "\n",
    "    df = df.drop(columns=[COLUMN_NAMES])\n",
    "    \n",
    "Drop the column of Goats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92c742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91b21638",
   "metadata": {},
   "source": [
    "to drop a row:\n",
    "    \n",
    "    df = df.drop(ROW_NUMBER)\n",
    "    \n",
    "Drop the data on Heol-y-bryn field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75c5ad9a",
   "metadata": {},
   "source": [
    "### Rearranging data  \n",
    "Panads does not care what order your data isin, but sometimes you want particular columns or rows at the right or top.  Here's how to do this.\n",
    "Make a list of your columns:  \n",
    "\n",
    "    cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcb107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a1cfee7",
   "metadata": {},
   "source": [
    "re-arrange by hand or by python list handling, for example: \n",
    "\n",
    "    cols_new = cols[-1:] + cols[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d7cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ce66493",
   "metadata": {},
   "source": [
    "Apply the new list order to the dataframe like this:  \n",
    "\n",
    "    df = df[cols_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b3610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67545207",
   "metadata": {},
   "source": [
    "To do the same with rows re-order by the index.  Start by making a list from the index:  \n",
    "\n",
    "    fields = df.index.values.tolist()\n",
    "    \n",
    "Take the last two fields and make them the first two using python list handling:  \n",
    "        \n",
    "        fields_new = fields[-2:] + fields[:-2]\n",
    "        \n",
    "Use the new list to order the rows:  \n",
    "\n",
    "    df2 = df.reindex(fields_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa8986",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a03b484",
   "metadata": {},
   "source": [
    "Re-arrange the dataframe to have both rows and columns alphabetically sorted.\n",
    "Use the python list sorting method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27669f06",
   "metadata": {},
   "source": [
    "### Sorting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a05f92",
   "metadata": {},
   "source": [
    "Sorting is easy - just specify column(s) and direction.  \n",
    "\n",
    "    df.sort_values(by=['col1', col2], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a369b21",
   "metadata": {},
   "source": [
    "sort by Sheep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e46de",
   "metadata": {},
   "source": [
    "sort by Sheep and Oats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbdd00",
   "metadata": {},
   "source": [
    "sort in descending order by Barley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0830c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dce05f6",
   "metadata": {},
   "source": [
    "### Transforming data   \n",
    "It's very straightforward to make a new column from an existing one.  \n",
    "You can treat numerical columns like numbers:\n",
    "\n",
    "    df[\"More_sheep\"] = df[\"Sheep\"]*50   \n",
    "    df[\"Per_sheep\"] = df[\"Barley\"]/df[\"Sheep\"]  \n",
    "    df[\"Stupid\"] = df[\"Field\"]*df[\"Sheep\"]  \n",
    "    \n",
    "numpy allows you to do fancier opperations\n",
    "\n",
    "    df[\"Logged_oats\"] = np.log(df[\"Oats\")\n",
    "\n",
    "and others....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd06a3",
   "metadata": {},
   "source": [
    "Make a column \"Cereals\" of the counts for Barley and Oats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ed5129e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee05f5f4",
   "metadata": {},
   "source": [
    "And \"Half_Cereals\" by diving this by two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87e5fb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf31ad8",
   "metadata": {},
   "source": [
    "Check to see the type of each column now.   \n",
    "\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206380d",
   "metadata": {},
   "source": [
    "The new column, product of an opperation is a float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6aa4b1",
   "metadata": {},
   "source": [
    "##### Working with text\n",
    "You can also opperate on columns of text in string format.  For example:\n",
    "\n",
    "    df.binomial = str(df.genus) + \"_\" + str(df.species)\n",
    "\n",
    "    df.protien = df.gene.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb3d88",
   "metadata": {},
   "source": [
    "Make a new column of Drainage and soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc025a",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Make another of Drainage and Oats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb7b4af",
   "metadata": {},
   "source": [
    "This fails as we have \"Oats\" coded as an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba571c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0fac82d",
   "metadata": {},
   "source": [
    "We could recode 'Oats' in the dataframe as text, \n",
    "\n",
    "    df = df.astype({\"Oats\": string})\n",
    "    \n",
    "But that might mess up later work.  Better to simply tell pandas to treat it as an string in the concatenation:\n",
    "\n",
    "    df[\"Oats\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a080f",
   "metadata": {},
   "source": [
    "Tidy up by dropping the new columns  Half_Cerales, Field_type and Oat_Drainage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f021ca",
   "metadata": {},
   "source": [
    "### Lambda functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da989019",
   "metadata": {},
   "source": [
    "What if you want to so something a bit fancier?  Lamba functions give you a lot of flexibility.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c75f0",
   "metadata": {},
   "source": [
    " We want to put in a colum showing the profitability of each field based on the yeild of each crop/flock.  \n",
    "We can define a lamba function and apply it across the dataframe  \n",
    "\n",
    "    df = df.assign(Profit=lambda x: (x['Sheep'] *10 +  x['Barley'] *5 +  x['Oats']*3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8d14c",
   "metadata": {},
   "source": [
    "We can use lamba to make changes in specific rows in a column and not others.  \n",
    "Maybe fields Lan-y-mor and Ffos_fawr flooded and produced no yeild.   \n",
    "We can replace their profits with 0.  \n",
    "  \n",
    "\n",
    "    df['Profit'] = df.apply(lambda row: 0 if row.name in (\"Lan-y-mor\", \"Ffos_fawr\") else row['Profit'], axis = 1)  \n",
    "    \n",
    "   \n",
    "axis = 1 specifies the change is to be made along a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ea8084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73db7d33",
   "metadata": {},
   "source": [
    "Replace current Drainage values with \"Good\" if Barley yield is greater than 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cf4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "710fad09",
   "metadata": {},
   "source": [
    "A useful nugget here is in logging columns.  logging a 0 gives infinity, so it is useful to ignore 0 values when logging.  You can do this this way:  \n",
    "\n",
    "    df['log_profit']=df['Profit'].apply(lambda x: 0 if x ==0 else np.log10(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4388bf9",
   "metadata": {},
   "source": [
    "You can also define your own function to apply.\n",
    "For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aef51a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_use(Sheep, Cereals):\n",
    "    if Sheep > 30:\n",
    "        return 'Livestock'\n",
    "    if Cereals > 1000:\n",
    "        return 'Arable'\n",
    "    else:\n",
    "        return 'Mixed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83237b0",
   "metadata": {},
   "source": [
    "This takes in two values (\"Sheep\" and \"Cereals\"), goes through an if loop, and outputs a new value - \"Mixed\" or \"Arable\" or \"Livestock\"  We apply it like this:  \n",
    "\n",
    "    df['Best_use'] = df.apply(lambda df: which_use(df['Sheep'],df['Cereals']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df471216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84edbc58",
   "metadata": {},
   "source": [
    "Make a new column called \"By_Sheep\" of Profit divided by Sheep for the Mixed use fields  \n",
    "Base it on the command used to remove profits from the flooded fields.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4d8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3266b00a",
   "metadata": {},
   "source": [
    "### Subsetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bbc47",
   "metadata": {},
   "source": [
    "How do we make a new dataframe of just the Clay Field data?  \n",
    "We can run over the Soil colum to create a list of \"True\" and \"False\" for each row depending on whether the Soil matches to \"Clay.  We then use this filter to subset the dataframe  \n",
    "\n",
    "    clay_df = df[df[\"Soil\"]==\"Clay\"]  \n",
    "    \n",
    "\"==\" is python for an exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef2489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1d948f5",
   "metadata": {},
   "source": [
    "We can use any combination or arithmetrical or boolean [true or false] statements  \n",
    "Make a dataframe of the Fields with more than 10 sheep in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2af4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48aa49cd",
   "metadata": {},
   "source": [
    "and another for non-clay soils. \n",
    "\"!=\" is python for is not equal to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595afaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b181cf",
   "metadata": {},
   "source": [
    "We can combine filters as either_or or and  \n",
    "\n",
    "    Clay_and_Ovid = df[(df[\"Sheep\"] > 10) & (df[\"Soil\"] == \"Clay\")]\n",
    "    Clay_OR_Ovid = df[(df[\"Sheep\"] > 10) | (df[\"Soil\"] == \"Clay\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3960d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90a02f10",
   "metadata": {},
   "source": [
    "We can select by multiple text matches by presenting a list of string to match  \n",
    "\n",
    "    Light_soil = df[df[\"Soil\"].isin([\"Loam\", \"Sand\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b350e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0ee5061",
   "metadata": {},
   "source": [
    "We can select by partial text matches.  We need to specify that the field contents are to be treated as a string and can then use a whole range of string opperations lies:\n",
    "\n",
    "    .contains()\n",
    "    .startswith()\n",
    "    .endswith()\n",
    "    \n",
    "Pick out hte rows with \"y' in the Field name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96ece8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9c6a7ce",
   "metadata": {},
   "source": [
    "Make a dataframe containing cases where the Barley yield is greater than the oat yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdebed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c704f9f",
   "metadata": {},
   "source": [
    "### Transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27762c0",
   "metadata": {},
   "source": [
    "We can easily transpose the whole data set to give a dataframe arranged with columns of individual fields and rows of values.  \n",
    "\n",
    "    Fields = df.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563cc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "728d2c52",
   "metadata": {},
   "source": [
    "Transpose it back again and make Field a column instead of an index (.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44f334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ea9c4cc",
   "metadata": {},
   "source": [
    "## Melting, casting, splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f043d86",
   "metadata": {},
   "source": [
    "### Tidy data  \n",
    "Melting, casting and splitting are your main tools for re-arranging the data into a tidy format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8dac31",
   "metadata": {},
   "source": [
    "Infection_TPM.csv is a typical way you might be presented with some data. This is transcripts per million reads for 6 samples for each of 7 genes.  Read it in fromt eh Datasets folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566a115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b65830",
   "metadata": {},
   "source": [
    "We can easily plot the gene expression levels for a tissue using barplot  \n",
    "\n",
    "    sns.barplot(x=\"Gene_ID\", y=\"Control_Flower\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48919c8",
   "metadata": {},
   "source": [
    "We could instead view the data by gene for each of the 6 samples.  \n",
    "Transpose the dataframe (.T), \n",
    "Make a new column names from the first row  \n",
    "Drop the first row  \n",
    "Plot NLR_1 expression by tissue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b59c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2adb66e9",
   "metadata": {},
   "source": [
    "### Splitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dda0e",
   "metadata": {},
   "source": [
    "But what if our focus is on infected and non-infected?  We have to do some juggling to get the dataframe in the right shape to plot useful graphs.  \n",
    "We need to make columns for Tissue and for Disease state from the index which combines both pieces of information.  We can split the text string on \"-\" like this:\n",
    "\n",
    "    df2.index.str.split('_')\n",
    "    \n",
    "We make this into two lists by:\n",
    "\n",
    "    *df2.index.str.split('_').tolist())\n",
    "    \n",
    "We can then specify the two new columns:  \n",
    "\n",
    "    df2['Disease'], df2['Tissue'] = zip(*df2.index.str.split('_').tolist())\n",
    "    \n",
    "We need to drop and re-set the index:  \n",
    "\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34fd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad534ac3",
   "metadata": {},
   "source": [
    "Now plot a barplot of NLR_1 expression by Tissues using hue = \"Disease\" to show the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7abb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb43923",
   "metadata": {},
   "source": [
    "### Melting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d59dc",
   "metadata": {},
   "source": [
    "This dataframe has 42 values:  \n",
    "    \n",
    "Gene, Disease states, and Tissues are variables  \n",
    "\n",
    "    Tissues - three possible levels  \n",
    "    Disease_state - 2 possible levels  \n",
    "    Genes - 7 possible levels  \n",
    "    \n",
    "Samples of plant organs in different disease states are observations  \n",
    "TPM counts are values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4e4a0",
   "metadata": {},
   "source": [
    "To make this dataset tidy we need to arrange it with the Genes,  Disease and Tissue as column headers and the TMP values in rows.  Melt will allow as to do this, going form wide format to long format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "To get a list of gene names to save having to type them.  \n",
    "\n",
    "    names = df.Gene_ID.tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9738b",
   "metadata": {},
   "source": [
    "use pd.melt() on df2.  \n",
    "The identity variable (id_vars) should be Tissues and Disease  \n",
    "The value variables (value_vars) should be the gene names  \n",
    "\n",
    "The name of the column of variable will be 'Gene_ID'  \n",
    "The name of the column of values will be 'TPM'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb10d13",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e28005",
   "metadata": {},
   "source": [
    "Now it's easy to plot the all the data by tissue using barplot\n",
    "\n",
    "    sns.barplot(x=\"Tissue\", y=\"TPM\", hue=\"Disease\", data=df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5a2e2",
   "metadata": {},
   "source": [
    "Or break it down by gene  \n",
    "\n",
    "    sns.catplot(x=\"Gene_ID\", y=\"TPM\", hue=\"Disease\", data=df3, kind=\"bar\")\n",
    "    \n",
    "or by tissue. \n",
    "\n",
    "    sns.catplot(x=\"Disease\", y=\"TPM\", hue=\"Tissue\", data=df3, kind=\"bar\")\n",
    "\n",
    "or as individual plots by Organ type\n",
    "\n",
    "    sns.catplot(x=\"Gene_ID\", y=\"TPM\", hue=\"Disease\", data=df3, col='Tissue', kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ddcc9",
   "metadata": {},
   "source": [
    "### Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f18b8",
   "metadata": {},
   "source": [
    "Casting is the oppoiste of melting.  Put the dataframe back into wide form using pd.pivot  \n",
    "\n",
    "index should be ['Disease', 'Tissue']\n",
    "columns should be 'Gene_ID'\n",
    "values should be 'TPM'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fa9a0",
   "metadata": {},
   "source": [
    "Notice we now have a multi-level index.  We will find out more about these in week 5. For the minute we will rest them to columns using  \n",
    "\n",
    "   df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1deca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
