{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061597cd",
   "metadata": {},
   "source": [
    "## Class 2  \n",
    "Downloading and entering data  \n",
    "Basic stats and plots  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a16b9",
   "metadata": {},
   "source": [
    "In the last class you entered data yourself.  Most of the data analysis you will be doing in this class, and likely in the future, will be using available datasets from which you can extract the data you want to examine.  In the class you will practise downloading data sets and opening them as pandas dataframe ready for cleaning and subsetting (next week).  We start with a few examples but feel free to find your own datasets to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e87bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bffc57",
   "metadata": {},
   "source": [
    "### Easy start. \n",
    "Pandas has a method for directly reading in excel sheets  \n",
    "\n",
    "    df = pd.read_excel('my_data.xls')  \n",
    "    \n",
    "and for reading in comma delineated files  \n",
    "\n",
    "    df = pd.read_csv('my_data.csv')  \n",
    "    \n",
    "read in count.xls and count.csv\n",
    "\n",
    "They are in the folder Datasets, which is in the folder above this one so the full path is:   \n",
    "    ../Datasets/count.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae3188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e06619a",
   "metadata": {},
   "source": [
    "count.txt is tab delineated.  We need to specify that the delimiter is tabs.  \n",
    "The parameter for delimiter is:\n",
    "\n",
    "   sep =\n",
    "   \n",
    "Read in count.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b12962",
   "metadata": {},
   "source": [
    "You can also read in tab delineated files using  \n",
    "\n",
    "    pd.read_table()\n",
    "    \n",
    "Check this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468379e9",
   "metadata": {},
   "source": [
    "Once it's in you can check the file structure is as you expect using  \n",
    "\n",
    "    df.info()  \n",
    "\n",
    "which gives you the full story, or \n",
    "    \n",
    "    df.dtypes  \n",
    "    \n",
    "which tells you how pandas has coded each column of data\n",
    "\n",
    "Compare both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb4eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52580ab1",
   "metadata": {},
   "source": [
    "There are 3 duff datasets in ../Datasets/\n",
    "\n",
    "    count_duff1.txt\n",
    "    count_duff2.txt\n",
    "    count_duff3.txt\n",
    " \n",
    "\n",
    "Read each into a dataframe with header, counts as integers and the field number as a string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b11c05",
   "metadata": {},
   "source": [
    "Useful parameters:\n",
    "\n",
    "    field separator: sep =\n",
    "    specify the null values: na_values =\n",
    "    set column headers: header=None (or specify a list)\n",
    "    Make data a specified type: dtype={'Column_A': 'string'})\n",
    "    ignore problematic rows: error_bad_lines=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fabf947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "685985b3",
   "metadata": {},
   "source": [
    "### The parts of a dataframe  \n",
    "We've defined column headers, but there are also row labels in the left-most column.  This is the dataframe index.  Read in the dataframe count_things.txt with column names set with this list. \n",
    "\n",
    "    col_names = [\"Meadow\", \"Pigs\",\"Cows\", \"Potatoes\",\"Turnips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff8191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4a8bb3",
   "metadata": {},
   "source": [
    "We can call the columns as a list and the index as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76591e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Meadow', 'Pigs', 'Cows', 'Potatoes', 'Turnips'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce9700",
   "metadata": {},
   "source": [
    "What does the index look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54288bf4",
   "metadata": {},
   "source": [
    "The column and row headers are python sequences and you can pull out individual lables the same way you would access part of the python list.  Check the fourth item in columns and the fourth item in the index:\n",
    "\n",
    "    df.columns[3]\n",
    "    \n",
    "    df.index[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57321599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaed20b4",
   "metadata": {},
   "source": [
    "You can re-name the index to more informative values - the field names  \n",
    "\n",
    "    df.set_index('Meadow', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb99626c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a06ea2",
   "metadata": {},
   "source": [
    "what happens if you don't set inplace=True?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be5481e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9201fec2",
   "metadata": {},
   "source": [
    "We can pick out individual values by specifiying column and index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3feb7a3",
   "metadata": {},
   "source": [
    "How many Cows in Meadow Hen_cae?  \n",
    "\n",
    "    df.at['Hen_cae','Cows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee680ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e7322e4",
   "metadata": {},
   "source": [
    "change this, adding a cow to the Hen_cae.  Use\n",
    "\n",
    "    df.at[index, column] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d566550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9ef1b7",
   "metadata": {},
   "source": [
    "### Trickier. \n",
    "Downloading data from a website and opening it.  \n",
    "NCBI has a list of sequence genomes and their assembly metrics:\n",
    "    \n",
    "    INTRODUCTION\n",
    "------------- \n",
    "species_genome_size.txt.gz provides the expected genome size for each species \n",
    "taxid with at least four assemblies in GenBank. The expected genome size range \n",
    "is used to identify outliers for a species that can result from errors. More\n",
    "information about how the genome size ranges are calculated can be found\n",
    "https://www.ncbi.nlm.nih.gov/assembly/help/genome-size-check/. \n",
    "\n",
    "\n",
    "The species_genome_size.txt.gz file has 5 tab-delimited columns. \n",
    "Header rows begin with '#\".\n",
    "\n",
    "Column  1: species_taxid\n",
    "   Taxonomic identifier of each species \n",
    "  \n",
    "Column  2: min_ungapped_length\n",
    "   Minimum expected ungapped genome size of an assembly for the species \n",
    "   \n",
    "Column  3: max_ungapped_length\n",
    "   Maximum expected ungapped genome size of an assembly for the species \n",
    "   \n",
    "Column  4: expected_ungapped_length\n",
    "   Median genome assembly size of assemblies for the species \n",
    "\n",
    "Column  5: number_of_genomes\n",
    "   Number of genomes used to calculate the expected size range\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87202264",
   "metadata": {},
   "source": [
    "We will down load the file (using wget), unzip it (using gunzip), check it's structure (using head) and read it in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50a1285",
   "metadata": {},
   "source": [
    "Using \"!\" at the start of a line informs the notebook that the following is bash and not python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791dc073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-04 11:11:16--  https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/species_genome_size.txt.gz\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 165.112.9.228, 130.14.250.13\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|165.112.9.228|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 59264 (58K) [application/x-gzip]\n",
      "Saving to: ‘species_genome_size.txt.gz’\n",
      "\n",
      "species_genome_size 100%[===================>]  57.88K   267KB/s    in 0.2s    \n",
      "\n",
      "2023-08-04 11:11:17 (267 KB/s) - ‘species_genome_size.txt.gz’ saved [59264/59264]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/species_genome_size.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84fd8f9",
   "metadata": {},
   "source": [
    "Unzip the datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "815bb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gunzip species_genome_size.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use \"! ls\" to check what files you have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce9b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67498a87",
   "metadata": {},
   "source": [
    "Check the data file's format using head as a bash command  \n",
    "\n",
    "    ! head -3 my_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7042a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55e47313",
   "metadata": {},
   "source": [
    "Read the data in. Which pd.read format would be best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745360b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d99392",
   "metadata": {},
   "source": [
    "Check that pandas has interpreted the type of data correctly using\n",
    "\n",
    "    dtypes\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365c03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8893515",
   "metadata": {},
   "source": [
    "#### What is the species with the most sequenced genomes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31edf14",
   "metadata": {},
   "source": [
    "df.max()['column'] will give you the maxiumum value for a column, but you want to also know the species id for this value.  \n",
    "\n",
    "Try sorting the whole dataframe using \n",
    "\n",
    "    df.sort_values(by=['Column_name'])  \n",
    "    \n",
    "You can use \n",
    "\n",
    "    .tail(N)\n",
    "    \n",
    "to show just N rows\n",
    "\n",
    "You can use \n",
    "\n",
    "    ascending=False\n",
    "  \n",
    "to show the highest values at the top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe33507",
   "metadata": {},
   "source": [
    "Make a quick histogram of the number of genomes using:\n",
    "\n",
    "    sns.boxplot(x=df[\"number_of_genomes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b18ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52e0a03c",
   "metadata": {},
   "source": [
    "You can check the identity of any genome at NCBI:  \n",
    "\n",
    "    https://www.ncbi.nlm.nih.gov/assembly/    \n",
    "\n",
    "search by txid[species_taxid]   \n",
    "txid[3707] is mustard, Brassica juncea  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a913f0a",
   "metadata": {},
   "source": [
    "Not all data is as tidy as the NCBI download.  Sometimes you need to exclude lines when you read in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a7148",
   "metadata": {},
   "source": [
    "### Tricky file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060c6b9",
   "metadata": {},
   "source": [
    "Open the excel sheet of data on agricultural productivy in the UK since 1973.  \n",
    "This is from:\n",
    "    \n",
    "   https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1004686/AUK-Chapter5-13jul23.ods\n",
    "        \n",
    "This was originally in ods format file. It COULD be read in directly by installing the odf engine, but to save complictions I've provided it as an excel file in Datasets.  \n",
    "\n",
    "    ../Datasets/AUK-Chapter5-13jul23.xlsx\n",
    "    \n",
    "Read it in and check format with  \n",
    "    \n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88cdb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a49d78",
   "metadata": {},
   "source": [
    "At least it reads in, but it's clearly not right - the first few rows are not data.  We need to exclude them, here we do this by setting as header the first line of data.\n",
    "\n",
    "Specify which of the input rows should be the header with \n",
    "    \n",
    "    header = N   \n",
    "    \n",
    "Remember that pandas is 0-indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25057d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99575988",
   "metadata": {},
   "source": [
    "We could also skip rows using \n",
    "\n",
    "    skiprows=N\n",
    "    \n",
    "What should N be here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456cacc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44ce9dd5",
   "metadata": {},
   "source": [
    "The end of the file is untidy as well - have a look with   \n",
    "    \n",
    "    df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541ba2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36330066",
   "metadata": {},
   "source": [
    "Use  \n",
    "\n",
    "    skipfooter=\n",
    "    \n",
    "To tidy this up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b59250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e412c176",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the dataframe is as you expect using df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e59819",
   "metadata": {},
   "source": [
    "Empty rows are automatically skipped (compare the excel file with what is read in), but rows which are moslty empty are filled with NaN.  We can remove these.  \n",
    "(inplace=True) makes the change happend on the original dataframe  \n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "or drop just the columns where there are missing values  \n",
    "\n",
    "    df.dropna(axis='columns',inplace=True)  \n",
    "    \n",
    "or the rows with more than 2 missing values  \n",
    "\n",
    "    df.dropna(thresh=2,inplace=True)  \n",
    "    \n",
    "or rows with missing values in specific columns  \n",
    "\n",
    "    df.dropna(subset=[1983, 1997],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6448b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed8b962",
   "metadata": {},
   "source": [
    "To examine this data it makes more sense to have outputs as columns.  We can transpose the dataframe using \n",
    "\n",
    "    df.T  \n",
    "    \n",
    "use \n",
    "\n",
    "    df.head(N) \n",
    "    \n",
    "to check this has worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0fec0",
   "metadata": {},
   "source": [
    "Now we have the years as the row names, and the types of output as row one.  \n",
    "How to fix this and make the types of output column headers?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f262b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    iloc[N]  \n",
    "\n",
    "gives row N values as a list.  We can use this to specify new column names.\n",
    "\n",
    "    df.columns = df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea745c4",
   "metadata": {},
   "source": [
    "Check with df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc4e46",
   "metadata": {},
   "source": [
    "We can now drop the redundant row 1.  There are lots of ways to do this!  \n",
    "\n",
    "Drop by index name of row  \n",
    "\n",
    "    df.drop(['Unnamed: 0'])  \n",
    "    \n",
    "Drop by index range  \n",
    "\n",
    "    df[1:]  \n",
    "    \n",
    "Drop by index location\n",
    "\n",
    "    df.drop(df.index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d7118",
   "metadata": {},
   "source": [
    "It will be useful to have the years as a column, not an index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a007542",
   "metadata": {},
   "source": [
    "Make the index into a new column using  \n",
    "\n",
    "    df.rest_index().  \n",
    "    \n",
    "Check it's worked using\n",
    "\n",
    "    df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7126e2",
   "metadata": {},
   "source": [
    "We also need to rename the new column. Specify which column to work on by putting the index in the square brackets and specify the new name.\n",
    "\n",
    "    df.columns.values[ ] = \"New_Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa100d07",
   "metadata": {},
   "source": [
    "Now we can check what we have.  Use\n",
    "\n",
    "    df.info()\n",
    "    \n",
    "to see what the columns are and which are numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956e1e9",
   "metadata": {},
   "source": [
    "All our data columns are coded as objects now (due to the text in the column names when they were row1).  We can fix this by applying pd.to_numeric across the dataframe  \n",
    "    \n",
    "    df = df.apply(pd.to_numeric)  \n",
    "    \n",
    "Check this has worked wiht   \n",
    "\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361ff7a",
   "metadata": {},
   "source": [
    "Now we can plot changes in agricultural output since 1973!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8bc86",
   "metadata": {},
   "source": [
    "Use sns.lineplot to look at changes in any agricultural output.  \n",
    "\n",
    "    sns.lineplot(x=df['Year'], y=df['plants and flowers'])\n",
    "    \n",
    "Use list(df.columns) to see your options for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d7db1",
   "metadata": {},
   "source": [
    "Can you see the effect of the foot and mouth outbreak?  the green revolution in grain productivity, the switch to imported fruit and vegetables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270019b",
   "metadata": {},
   "source": [
    "### Saving dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc48f5",
   "metadata": {},
   "source": [
    "Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e84c826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('UK_agriculture.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca61a3",
   "metadata": {},
   "source": [
    "Save as excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7c13f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('UK_agriculture.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a6c5b",
   "metadata": {},
   "source": [
    "What happens if you leave off 'index=False'?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c7787",
   "metadata": {},
   "source": [
    "#### Pickling  \n",
    "Sometime you are working solely within python and want to preserve the syntax exactly rather than writing to a flat csv or excel file\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9685f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('UK_crops.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5d429",
   "metadata": {},
   "source": [
    "Reading from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc2009cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('UK_crops.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6ad75",
   "metadata": {},
   "source": [
    "Checking contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "960c1fac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69 entries, 0 to 68\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Production(2015=100)  65 non-null     object \n",
      " 1   1973                  64 non-null     float64\n",
      " 2   1974                  64 non-null     float64\n",
      " 3   1975                  64 non-null     float64\n",
      " 4   1976                  64 non-null     float64\n",
      " 5   1977                  64 non-null     float64\n",
      " 6   1978                  64 non-null     float64\n",
      " 7   1979                  64 non-null     float64\n",
      " 8   1980                  64 non-null     float64\n",
      " 9   1981                  64 non-null     float64\n",
      " 10  1982                  64 non-null     float64\n",
      " 11  1983                  64 non-null     float64\n",
      " 12  1984                  64 non-null     float64\n",
      " 13  1985                  64 non-null     float64\n",
      " 14  1986                  64 non-null     float64\n",
      " 15  1987                  64 non-null     float64\n",
      " 16  1988                  64 non-null     float64\n",
      " 17  1989                  64 non-null     float64\n",
      " 18  1990                  64 non-null     float64\n",
      " 19  1991                  64 non-null     float64\n",
      " 20  1992                  64 non-null     float64\n",
      " 21  1993                  64 non-null     float64\n",
      " 22  1994                  64 non-null     float64\n",
      " 23  1995                  64 non-null     float64\n",
      " 24  1996                  64 non-null     float64\n",
      " 25  1997                  64 non-null     float64\n",
      " 26  1998                  64 non-null     float64\n",
      " 27  1999                  64 non-null     float64\n",
      " 28  2000                  64 non-null     float64\n",
      " 29  2001                  64 non-null     float64\n",
      " 30  2002                  64 non-null     float64\n",
      " 31  2003                  64 non-null     float64\n",
      " 32  2004                  64 non-null     float64\n",
      " 33  2005                  64 non-null     float64\n",
      " 34  2006                  64 non-null     float64\n",
      " 35  2007                  64 non-null     float64\n",
      " 36  2008                  64 non-null     float64\n",
      " 37  2009                  64 non-null     float64\n",
      " 38  2010                  64 non-null     float64\n",
      " 39  2011                  64 non-null     float64\n",
      " 40  2012                  64 non-null     float64\n",
      " 41  2013                  64 non-null     float64\n",
      " 42  2014                  64 non-null     float64\n",
      " 43  2015                  64 non-null     float64\n",
      " 44  2016                  64 non-null     float64\n",
      " 45  2017                  64 non-null     float64\n",
      " 46  2018                  64 non-null     float64\n",
      " 47  2019                  64 non-null     float64\n",
      " 48  2020                  64 non-null     float64\n",
      "dtypes: float64(48), object(1)\n",
      "memory usage: 26.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d274f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
